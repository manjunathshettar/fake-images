{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((img_height, img_width)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './archive/train/'\n",
    "train_path_real = './archive/train/REAL/'\n",
    "test_path = './archive/test/'\n",
    "test_path_real = './archive/test/REAL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root = train_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root = test_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 3, 32, 32])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "img.transpose_(0, 2)\n",
    "#display the image\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "label = train_labels[1]\n",
    "#plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_set, X_test, y_set, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_set, y_set, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels = 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels = 32, kernel_size=5)\n",
    "        #self.conv = nn.Conv2d(in_channels=3, out_channels = 32, kernel_size=(3,3))\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 3, 32, 32]) torch.Size([11, 3, 32, 32]) torch.Size([13, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert tensors to floats\n",
    "X_train = X_train.float()\n",
    "X_val = X_val.float()\n",
    "X_test = X_test.float()\n",
    "y_train = y_train.float()\n",
    "y_val = y_val.float()\n",
    "y_test = y_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "def train(epochs, model, perm=torch.arange(0, 784).long()):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "      for batch_idx, (data, target) in enumerate(trainloader):\n",
    "          # send to device\n",
    "          data, target = data.to(device), target.to(device)\n",
    "          \n",
    "          data = data.float()\n",
    "          target = target.float()\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          output = model(data)\n",
    "          loss = F.binary_cross_entropy(output, target)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          if batch_idx % 100 == 0:\n",
    "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                  epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                  100. * batch_idx / len(trainloader), loss.item()))\n",
    "            \n",
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in testloader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        data = data.float()\n",
    "        target = target.float()\n",
    "        # permute pixels\n",
    "        output = model(data)\n",
    "        test_loss += F.binary_cross_entropy(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "        pred = (output > 0.5).float()                                                                \n",
    "        correct += (pred == target).cpu().sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    accuracy = 100. * correct / len(testloader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testloader.dataset),\n",
    "        accuracy))\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/100000 (0%)]\tLoss: 0.694915\n",
      "Train Epoch: 0 [6400/100000 (6%)]\tLoss: 0.703660\n",
      "Train Epoch: 0 [12800/100000 (13%)]\tLoss: 0.392724\n",
      "Train Epoch: 0 [19200/100000 (19%)]\tLoss: 0.324968\n",
      "Train Epoch: 0 [25600/100000 (26%)]\tLoss: 0.253654\n",
      "Train Epoch: 0 [32000/100000 (32%)]\tLoss: 0.432847\n",
      "Train Epoch: 0 [38400/100000 (38%)]\tLoss: 0.170112\n",
      "Train Epoch: 0 [44800/100000 (45%)]\tLoss: 0.256195\n",
      "Train Epoch: 0 [51200/100000 (51%)]\tLoss: 0.318071\n",
      "Train Epoch: 0 [57600/100000 (58%)]\tLoss: 0.123973\n",
      "Train Epoch: 0 [64000/100000 (64%)]\tLoss: 0.210147\n",
      "Train Epoch: 0 [70400/100000 (70%)]\tLoss: 0.185180\n",
      "Train Epoch: 0 [76800/100000 (77%)]\tLoss: 0.245551\n",
      "Train Epoch: 0 [83200/100000 (83%)]\tLoss: 0.253817\n",
      "Train Epoch: 0 [89600/100000 (90%)]\tLoss: 0.315371\n",
      "Train Epoch: 0 [96000/100000 (96%)]\tLoss: 0.288296\n",
      "Train Epoch: 1 [0/100000 (0%)]\tLoss: 0.260165\n",
      "Train Epoch: 1 [6400/100000 (6%)]\tLoss: 0.289908\n",
      "Train Epoch: 1 [12800/100000 (13%)]\tLoss: 0.234039\n",
      "Train Epoch: 1 [19200/100000 (19%)]\tLoss: 0.237266\n",
      "Train Epoch: 1 [25600/100000 (26%)]\tLoss: 0.186985\n",
      "Train Epoch: 1 [32000/100000 (32%)]\tLoss: 0.224837\n",
      "Train Epoch: 1 [38400/100000 (38%)]\tLoss: 0.226157\n",
      "Train Epoch: 1 [44800/100000 (45%)]\tLoss: 0.362068\n",
      "Train Epoch: 1 [51200/100000 (51%)]\tLoss: 0.120483\n",
      "Train Epoch: 1 [57600/100000 (58%)]\tLoss: 0.184173\n",
      "Train Epoch: 1 [64000/100000 (64%)]\tLoss: 0.212450\n",
      "Train Epoch: 1 [70400/100000 (70%)]\tLoss: 0.200094\n",
      "Train Epoch: 1 [76800/100000 (77%)]\tLoss: 0.148649\n",
      "Train Epoch: 1 [83200/100000 (83%)]\tLoss: 0.129940\n",
      "Train Epoch: 1 [89600/100000 (90%)]\tLoss: 0.108018\n",
      "Train Epoch: 1 [96000/100000 (96%)]\tLoss: 0.177768\n",
      "Train Epoch: 2 [0/100000 (0%)]\tLoss: 0.143822\n",
      "Train Epoch: 2 [6400/100000 (6%)]\tLoss: 0.151558\n",
      "Train Epoch: 2 [12800/100000 (13%)]\tLoss: 0.087274\n",
      "Train Epoch: 2 [19200/100000 (19%)]\tLoss: 0.239092\n",
      "Train Epoch: 2 [25600/100000 (26%)]\tLoss: 0.107093\n",
      "Train Epoch: 2 [32000/100000 (32%)]\tLoss: 0.199623\n",
      "Train Epoch: 2 [38400/100000 (38%)]\tLoss: 0.082108\n",
      "Train Epoch: 2 [44800/100000 (45%)]\tLoss: 0.115437\n",
      "Train Epoch: 2 [51200/100000 (51%)]\tLoss: 0.109889\n",
      "Train Epoch: 2 [57600/100000 (58%)]\tLoss: 0.178647\n",
      "Train Epoch: 2 [64000/100000 (64%)]\tLoss: 0.221916\n",
      "Train Epoch: 2 [70400/100000 (70%)]\tLoss: 0.250899\n",
      "Train Epoch: 2 [76800/100000 (77%)]\tLoss: 0.178217\n",
      "Train Epoch: 2 [83200/100000 (83%)]\tLoss: 0.242871\n",
      "Train Epoch: 2 [89600/100000 (90%)]\tLoss: 0.058092\n",
      "Train Epoch: 2 [96000/100000 (96%)]\tLoss: 0.099097\n",
      "Train Epoch: 3 [0/100000 (0%)]\tLoss: 0.172256\n",
      "Train Epoch: 3 [6400/100000 (6%)]\tLoss: 0.117748\n",
      "Train Epoch: 3 [12800/100000 (13%)]\tLoss: 0.085659\n",
      "Train Epoch: 3 [19200/100000 (19%)]\tLoss: 0.248558\n",
      "Train Epoch: 3 [25600/100000 (26%)]\tLoss: 0.101323\n",
      "Train Epoch: 3 [32000/100000 (32%)]\tLoss: 0.136568\n",
      "Train Epoch: 3 [38400/100000 (38%)]\tLoss: 0.159378\n",
      "Train Epoch: 3 [44800/100000 (45%)]\tLoss: 0.074684\n",
      "Train Epoch: 3 [51200/100000 (51%)]\tLoss: 0.159497\n",
      "Train Epoch: 3 [57600/100000 (58%)]\tLoss: 0.123897\n",
      "Train Epoch: 3 [64000/100000 (64%)]\tLoss: 0.109083\n",
      "Train Epoch: 3 [70400/100000 (70%)]\tLoss: 0.105460\n",
      "Train Epoch: 3 [76800/100000 (77%)]\tLoss: 0.144706\n",
      "Train Epoch: 3 [83200/100000 (83%)]\tLoss: 0.246497\n",
      "Train Epoch: 3 [89600/100000 (90%)]\tLoss: 0.178211\n",
      "Train Epoch: 3 [96000/100000 (96%)]\tLoss: 0.149084\n",
      "Train Epoch: 4 [0/100000 (0%)]\tLoss: 0.191189\n",
      "Train Epoch: 4 [6400/100000 (6%)]\tLoss: 0.099635\n",
      "Train Epoch: 4 [12800/100000 (13%)]\tLoss: 0.182672\n",
      "Train Epoch: 4 [19200/100000 (19%)]\tLoss: 0.123444\n",
      "Train Epoch: 4 [25600/100000 (26%)]\tLoss: 0.184171\n",
      "Train Epoch: 4 [32000/100000 (32%)]\tLoss: 0.119727\n",
      "Train Epoch: 4 [38400/100000 (38%)]\tLoss: 0.174040\n",
      "Train Epoch: 4 [44800/100000 (45%)]\tLoss: 0.167518\n",
      "Train Epoch: 4 [51200/100000 (51%)]\tLoss: 0.178636\n",
      "Train Epoch: 4 [57600/100000 (58%)]\tLoss: 0.055886\n",
      "Train Epoch: 4 [64000/100000 (64%)]\tLoss: 0.182506\n",
      "Train Epoch: 4 [70400/100000 (70%)]\tLoss: 0.114995\n",
      "Train Epoch: 4 [76800/100000 (77%)]\tLoss: 0.172597\n",
      "Train Epoch: 4 [83200/100000 (83%)]\tLoss: 0.113761\n",
      "Train Epoch: 4 [89600/100000 (90%)]\tLoss: 0.074125\n",
      "Train Epoch: 4 [96000/100000 (96%)]\tLoss: 0.076574\n"
     ]
    }
   ],
   "source": [
    "train(5, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1514, Accuracy: 18794/20000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model)\n",
    "torch.jit.save(model_scripted, \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
